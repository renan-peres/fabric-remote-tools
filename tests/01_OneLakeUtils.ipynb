{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"fabric_remote_tools: OneLake CRUD Operations\"\n",
    "author: \"Renan Peres\"\n",
    "date: \"July 01, 2024\"\n",
    "format:\n",
    "    html:\n",
    "        theme: \n",
    "            light: flatly\n",
    "            dark: darkly\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "        code-tools: \n",
    "            source: true\n",
    "            toggle: true\n",
    "            # caption: none\n",
    "        code-copy: true\n",
    "        code-overflow: wrap\n",
    "        smooth-scroll: true       \n",
    "        page-layout: full\n",
    "        toc: true\n",
    "        toc-location: left\n",
    "        lightbox: true\n",
    "    ipynb:\n",
    "        output-file: output-file: \"fabric_remote_tools-OneLake-CRUD-Operations.ipynb\"\n",
    "        highlight-style: dracula\n",
    "        code-fold: show\n",
    "    pdf: default\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OneLake (Lakehouse) CRUD Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Package & Load Modules\n",
    "# %pip install https://github.com/renan-peres/fabric-remote-tools/raw/main/fabric_remote_tools-0.1.1.tar.gz\n",
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load Environmet Variables & Secrets (.env File)\n",
    "account_name = os.getenv(\"ACCOUNT_NAME\")\n",
    "workspace_id = os.getenv(\"WORKSPACE_ID\")\n",
    "lakehouse_id = os.getenv(\"LAKEHOUSE_ID\")\n",
    "github_token = os.getenv(\"GH_PERSONAL_ACCESS_TOKEN\")\n",
    "github_username = os.getenv(\"GH_USERNAME\")\n",
    "gh_repo_name = os.getenv(\"GH_REPO_NAME\")\n",
    "organization_url = os.getenv(\"ADO_ORGANIZATIONAL_URL\")\n",
    "personal_access_token = os.getenv(\"ADO_PERSONAL_ACCESS_TOKEN\")\n",
    "project_name = os.getenv(\"ADO_PROJECT_NAME\")\n",
    "repo_name = os.getenv(\"ADO_REPO_NAME\")\n",
    "\n",
    "# Get Authentication Token\n",
    "token = FabricAuth.get_DefaultAzureCredential()\n",
    "\n",
    "# Get File System Client\n",
    "file_system_client = FabricAuth.get_FileSystemClient(token, account_name, workspace_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write Local DeltaLake Tables to Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Table\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables/venture_funding_deals_delta_partitioned\",\n",
    "    target_path=\"Tables/local_venture_funding_deals_delta_partitioned\"\n",
    ")\n",
    "\n",
    "# Multiple Tables in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Tables\",\n",
    "    target_path=\"Tables/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write Local Files/Folders to Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files\",\n",
    "    target_path=\"Files/\"\n",
    ")\n",
    "\n",
    "# Individual Subfolder inside a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso\",\n",
    "    target_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Specific File in a Folder\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"local\",\n",
    "    source_path=\"../assets/data/Files/Contoso/contoso_sales.csv\",\n",
    "    target_path=\"Files/Contoso/contoso_sales.csv\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write GitHub (Public Repo) to Lakehouse** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/Polars-Cookbook\"\n",
    ")\n",
    "\n",
    "# Single Table (Delta) in Repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Tables/github_venture_funding_deals_delta\",\n",
    "    folder_path=\"data/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github\",\n",
    "    source_path=\"https://github.com/renan-peres/Polars-Cookbook.git\",\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write GitHub (Private Repo) to Lakehouse** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=f\"Files/GitHub/{gh_repo_name}\"\n",
    ")\n",
    "\n",
    "# Specific folder from GitHub private repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"github_private\",\n",
    "    github_token=github_token,\n",
    "    github_username=github_username,\n",
    "    repo_name=gh_repo_name,\n",
    "    target_path=\"Files/GitHub/data\",\n",
    "    folder_path=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write Azure DevOps (Private Repo) to Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=f\"Files/AzureDevOps/{repo_name}\",\n",
    ")\n",
    "\n",
    "# Specific folder from Azure DevOps repository\n",
    "OneLakeUtils.write_to_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    upload_from=\"azure_devops\",\n",
    "    project_name=project_name,\n",
    "    repo_name=repo_name,\n",
    "    organization_url=organization_url,\n",
    "    personal_access_token=personal_access_token,\n",
    "    target_path=\"Files/AzureDevOps/data\",\n",
    "    folder_path=\"/data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **List Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List All Tables in Lakehouse\n",
    "OneLakeUtils.list_items(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    ,target_directory_path=\"Tables\"\n",
    "    #  ,print_output= True # Optional\n",
    ")\n",
    "\n",
    "# List All Files in Lakehouse\n",
    "OneLakeUtils.list_items(\n",
    "    file_system_client=file_system_client\n",
    "    ,lakehouse_id=lakehouse_id\n",
    "    ,target_directory_path=\"Files\"\n",
    "    #  ,print_output= True # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download a single table\n",
    "# OneLakeUtils.download_from_lakehouse(\n",
    "#     file_system_client=file_system_client,\n",
    "#     target_file_path=\"Tables/venture_funding_deals_delta\",\n",
    "#     lakehouse_id=lakehouse_id\n",
    "# )\n",
    "\n",
    "# # Download a single file\n",
    "# OneLakeUtils.download_from_lakehouse(\n",
    "#     file_system_client=file_system_client,\n",
    "#     target_file_path=\"Files/Contoso/contoso_sales.csv\",\n",
    "#     lakehouse_id=lakehouse_id\n",
    "# )\n",
    "\n",
    "# # Download a subfolder\n",
    "# OneLakeUtils.download_from_lakehouse(\n",
    "#     file_system_client=file_system_client,\n",
    "#     target_file_path=\"Files/Contoso/\",\n",
    "#     lakehouse_id=lakehouse_id\n",
    "# )\n",
    "\n",
    "# # Download all tables\n",
    "# OneLakeUtils.download_from_lakehouse(\n",
    "#     file_system_client=file_system_client,\n",
    "#     target_file_path=\"Tables/\",\n",
    "#     lakehouse_id=lakehouse_id\n",
    "# )\n",
    "\n",
    "# Download specific tables\n",
    "filter_func = lambda path: path >= f\"{lakehouse_id}/Tables/dim_salesordershippingaddress\"\n",
    "\n",
    "OneLakeUtils.download_from_lakehouse(\n",
    "    file_system_client=file_system_client,\n",
    "    target_file_path=\"Tables/\",\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    filter_func=filter_func\n",
    ")\n",
    "\n",
    "# # Download all files\n",
    "# OneLakeUtils.download_from_lakehouse(\n",
    "#     file_system_client=file_system_client,\n",
    "#     target_file_path=\"Files/\",\n",
    "#     lakehouse_id=lakehouse_id\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Delete Items from Lakehouse (Files/Tables)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a single table\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Tables/venture_funding_deals_delta\"\n",
    ")\n",
    "\n",
    "# Delete a single file\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/Contoso/contoso_sales.csv\"\n",
    ")\n",
    "\n",
    "# Delete a subfolder\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/Contoso\"\n",
    ")\n",
    "\n",
    "# Delete all tables\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Tables/\"\n",
    ")\n",
    "\n",
    "# Delete all files\n",
    "OneLakeUtils.delete_file(\n",
    "    file_system_client=file_system_client,\n",
    "    lakehouse_id=lakehouse_id,\n",
    "    lakehouse_dir_path=\"Files/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DeltaLake (Tables) UPSERT Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Package & Load Modules\n",
    "# %pip install https://github.com/renan-peres/fabric-remote-tools/raw/main/fabric_remote_tools-0.1.1.tar.gz\n",
    "from fabric_remote_tools import FabricAuth, OneLakeUtils\n",
    "from deltalake.writer import write_deltalake\n",
    "from deltalake import DeltaTable\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Load Environmet Variables & Secrets (.env File)\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\")\n",
    "lakehouse_name = os.getenv(\"LAKEHOUSE_NAME\")\n",
    "table_name = \"Tables/venture_funding_deals_delta\"\n",
    "table_path = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/{table_name}\"\n",
    "\n",
    "# Get File System Client\n",
    "file_system_client = FabricAuth().get_ClientSecretCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read DeltaLake Table from Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┬─────────────────┬──────────────────────┬───┬──────────────────────┬───────────────┐\n",
       "│       Company        │     Amount      │    Lead investors    │ … │       Industry       │ Date reported │\n",
       "│       varchar        │     varchar     │       varchar        │   │       varchar        │    varchar    │\n",
       "├──────────────────────┼─────────────────┼──────────────────────┼───┼──────────────────────┼───────────────┤\n",
       "│ OpenAI               │ $10,000,000,000 │ Microsoft            │ … │ Artificial intelli…  │ 1/23/23       │\n",
       "│ Stripe               │ $6,500,000,000  │ n/a                  │ … │ Fintech              │ 3/15/23       │\n",
       "│ Inflection AI        │ $1,300,000,000  │ Microsoft, Reid Ho…  │ … │ Artificial intelli…  │ 6/29/23       │\n",
       "│ Anthropic            │ $1,250,000,000  │ Amazon               │ … │ Artificial intelli…  │ 9/25/23       │\n",
       "│ Generate Capital     │ $1,030,900,000  │ n/a                  │ … │ Energy               │ 1/6/23        │\n",
       "│ Redwood Materials    │ $1,000,000,000  │ Goldman Sachs Asse…  │ … │ Renewable energy     │ 8/29/23       │\n",
       "│ Stack AV             │ $1,000,000,000  │ SoftBand Group       │ … │ Autonomous vehicles  │ 9/7/23        │\n",
       "│ SandboxAQ            │ $500,000,000    │ n/a                  │ … │ Artifical intellig…  │ 2/14/23       │\n",
       "│ Lessen               │ $500,000,000    │ n/a                  │ … │ Real estate          │ 1/11/23       │\n",
       "│ Rippling             │ $500,000,000    │ Greenoaks            │ … │ Human resources      │ 3/17/23       │\n",
       "│   ·                  │      ·          │  ·                   │ · │       ·              │    ·          │\n",
       "│   ·                  │      ·          │  ·                   │ · │       ·              │    ·          │\n",
       "│   ·                  │      ·          │  ·                   │ · │       ·              │    ·          │\n",
       "│ BitGo                │ $100,000,000    │ n/a                  │ … │ Cryptocurrency       │ 8/16/23       │\n",
       "│ Modular              │ $100,000,000    │ General Catalyst     │ … │ Artificial intelli…  │ 8/24/23       │\n",
       "│ Apollo.io            │ $100,000,000    │ Bain Capital Ventu…  │ … │ Sales                │ 8/29/23       │\n",
       "│ Beta Bionics         │ $100,000,000    │ Sands Capital, Ome…  │ … │ Health care          │ 8/30/23       │\n",
       "│ Professional Fight…  │ $100,000,000    │ SRJ Sports Investm…  │ … │ Sports               │ 8/30/23       │\n",
       "│ Inceptive            │ $100,000,000    │ NVentures, Andrees…  │ … │ Biotech              │ 9/7/23        │\n",
       "│ Vesper Energy        │ $100,000,000    │ GCM Grosvenor        │ … │ Energy               │ 9/13/23       │\n",
       "│ Writer               │ $100,000,000    │ Iconiq Growth        │ … │ Artificial intelli…  │ 9/18/23       │\n",
       "│ Pryon                │ $100,000,000    │ US Innovative Tech…  │ … │ Artificial intelli…  │ 9/19/23       │\n",
       "│ Openly               │ $100,000,000    │ Eden Global Partners │ … │ Insurance            │ 9/21/23       │\n",
       "├──────────────────────┴─────────────────┴──────────────────────┴───┴──────────────────────┴───────────────┤\n",
       "│ 211 rows (20 shown)                                                                  6 columns (5 shown) │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = OneLakeUtils().read_deltalake(\n",
    "    file_system_client=file_system_client,\n",
    "    table_path=table_path,\n",
    "    engine='duckdb',  # Supported options: 'duckdb', 'polars'\n",
    "    # version=2,  # Optional: specify the version to read\n",
    "    # row_limit=10  # Optional\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query/Transform DataFrame with DuckDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install magic_duckdb --upgrade --quiet\n",
    "%load_ext magic_duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>column_type</th>\n",
       "      <th>null</th>\n",
       "      <th>key</th>\n",
       "      <th>default</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amount</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead investors</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valuation</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Industry</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Date reported</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>YES</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      column_name column_type null   key default extra\n",
       "0         Company     VARCHAR  YES  None    None  None\n",
       "1          Amount     VARCHAR  YES  None    None  None\n",
       "2  Lead investors     VARCHAR  YES  None    None  None\n",
       "3       Valuation     VARCHAR  YES  None    None  None\n",
       "4        Industry     VARCHAR  YES  None    None  None\n",
       "5   Date reported     VARCHAR  YES  None    None  None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dql\n",
    "PRAGMA disable_print_progress_bar;\n",
    "SUMMARIZE df;\n",
    "DESCRIBE SELECT * FROM df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count\n",
       "0     20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dql\n",
    "CREATE OR REPLACE TABLE df_tranf AS \n",
    "    SELECT *\n",
    "    FROM df\n",
    "    LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write DataFrame as a DeltaLake Table to Lakehouse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to Lakehouse\n",
    "write_deltalake(\n",
    "    table_or_uri=table_path\n",
    "    ,storage_options=file_system_client\n",
    "    # ,data=df.to_arrow() # Polars DF\n",
    "    ,data=duckdb.sql(\"SELECT * FROM df_tranf\").arrow() # DuckDB (arrow DF)\n",
    "    ,mode=\"append\" # Supported: 'append', 'overwrite'\n",
    "    ,engine=\"rust\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Describe Table History (Time Travel)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>clientVersion</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-04 16:33:18.813</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append'}</td>\n",
       "      <td>delta-rs.0.18.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-04 14:27:40.407</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Append'}</td>\n",
       "      <td>delta-rs.0.18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-14 19:15:06.777</td>\n",
       "      <td>CREATE TABLE</td>\n",
       "      <td>{'protocol': '{\"minReaderVersion\":1,\"minWriter...</td>\n",
       "      <td>delta-rs.0.15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp     operation  \\\n",
       "0 2024-07-04 16:33:18.813         WRITE   \n",
       "1 2024-07-04 14:27:40.407         WRITE   \n",
       "2 2023-10-14 19:15:06.777  CREATE TABLE   \n",
       "\n",
       "                                 operationParameters    clientVersion  version  \n",
       "0                                 {'mode': 'Append'}  delta-rs.0.18.1        2  \n",
       "1                                 {'mode': 'Append'}  delta-rs.0.18.0        1  \n",
       "2  {'protocol': '{\"minReaderVersion\":1,\"minWriter...  delta-rs.0.15.0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the DeltaTable\n",
    "dt = DeltaTable(table_path)\n",
    "\n",
    "# Retrieve the full history of the DeltaTable\n",
    "history = dt.history()\n",
    "\n",
    "# Convert the history list to a pandas DataFrame\n",
    "history_df = pd.DataFrame(history)\n",
    "\n",
    "# Parse the timestamp column\n",
    "history_df['timestamp'] = pd.to_datetime(history_df['timestamp'], unit='ms')\n",
    "\n",
    "# Display the DataFrame, sorted by version in descending order\n",
    "display(history_df.sort_values(by='version', ascending=False).head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
